{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "870d3673",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c7c4cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_fns import get_yelp_stars\n",
    "from eval_utils import predict_stuff\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8072177b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForConditionalGenerationMultipleHeads were not initialized from the model checkpoint at t5-large and are newly initialized: ['encoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primary mode: exp_applies_predictor\n",
      "splicing parts from pretrained model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-large and are newly initialized: ['encoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only loading base model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-large and are newly initialized: ['encoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primary mode: exp_applies_predictor\n"
     ]
    }
   ],
   "source": [
    "from eval_utils import load_model\n",
    "\n",
    "path_name = '/u/scr/smurty/LanguageExplanations/trained_models/t5-large-sst-no-exp'\n",
    "model_obj = load_model(path_name, primary_mode='exp_applies_predictor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1dc6e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset yelp_polarity (/u/scr/smurty/yelp_polarity/plain_text/1.0.0/a770787b2526bdcbfc29ac2d9beb8e820fbc15a03afd3ebc4fb9d8529de57544)\n"
     ]
    }
   ],
   "source": [
    "tests_yelp = get_yelp_stars()\n",
    "inps, labels = tests_yelp[0], tests_yelp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7b8d795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc7aa43983c4efc9ba237ed4eced712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9312736443883984\n"
     ]
    }
   ],
   "source": [
    "no_exps = [('', ex) for ex in inps]\n",
    "no_exp_probs = predict_stuff(no_exps, [0]*len(no_exps), model_obj, 'p1', verbose=False, mode='task_predictor')\n",
    "no_exp_preds = no_exp_probs.argmax(axis=1)\n",
    "\n",
    "print(np.mean(no_exp_preds == labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d560cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.919609079445145\n"
     ]
    }
   ],
   "source": [
    "def rule_based_patch(inp, orig_pred):\n",
    "    keywords = [' 0 star', ' 1 star', ' 2 star', \n",
    "               ' zero star', ' one star', ' two star']\n",
    "    if any(keyword in inp for keyword in keywords):\n",
    "        return 0\n",
    "    else:\n",
    "        return orig_pred\n",
    "\n",
    "rule_preds = np.array([rule_based_patch(inp, pred) for inp, pred in zip(inps, no_exp_preds)])\n",
    "print(np.mean(rule_preds == labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e19b58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640eb43c014a4cc9a56b8e3b16b9074e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9082597730138714\n"
     ]
    }
   ],
   "source": [
    "prompt ='If review gives 0, 1, 2 stars, then label is negative'\n",
    "import itertools\n",
    "def get_prompting(data, prompt, examine=False):\n",
    "    prompted_inps = [(prompt, ex) for ex in data[0]]\n",
    "    probs = predict_stuff(prompted_inps, itertools.repeat(0), \n",
    "                          model_obj, 'p1', verbose=False, mode='task_predictor')\n",
    "    #print(np.mean(probs.argmax(axis=1)==data[1]))\n",
    "    return probs.argmax(axis=1)\n",
    "    \n",
    "\n",
    "\n",
    "prompt_preds = get_prompting((inps, labels), prompt, examine=False)\n",
    "print(np.mean(prompt_preds == labels))        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e91289b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('wcr.pickle', 'rb') as reader:\n",
    "    dataset = pickle.load(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1c53c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Input: ...the print is so sharking, and i love the way it looks on the model -- but i'm a more curvy figure, and the boxy-ish cut plus rather stuff fabric in front is incredibly unflattering. ordinarily i love everything made by maeve, but this one sadly must be returned... on a thinner/straighter-shaped person i expect it would be great\", 'negative')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24e3776da3a4751822f5fe3c528d431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:14<00:00,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8958547447756081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "explanations = [('review says fit is boxy',[1,0]),\n",
    "               (\"review contains words or phrases like needs to be returned\", [1, 0]),\n",
    "               (\"review contains words or phrases like needs to be exchanged\", [1,0])]\n",
    "    \n",
    "\n",
    "no_exps = [('', data) for data in dataset[0]]\n",
    "baseline_rec_out = predict_stuff(no_exps, [0]*len(no_exps), model_obj, 'p1', verbose=True, mode='task_predictor')\n",
    "base_preds = baseline_rec_out.argmax(axis=1)\n",
    "\n",
    "print(np.mean(base_preds == dataset[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c08b23b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8999657416923604\n"
     ]
    }
   ],
   "source": [
    "def rule_based_patch2(inp, orig_pred):\n",
    "    keywords = ['boxy', \n",
    "               'needs to be returned']\n",
    "    if any(keyword in inp for keyword in keywords):\n",
    "        return 0\n",
    "    else:\n",
    "        return orig_pred\n",
    "    \n",
    "rule_preds = np.array([rule_based_patch2(inp, orig_pred) for inp, orig_pred in zip(dataset[0], base_preds)])\n",
    "print(np.mean(rule_preds == dataset[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3657d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shikhar-basic",
   "language": "python",
   "name": "shikhar-basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
